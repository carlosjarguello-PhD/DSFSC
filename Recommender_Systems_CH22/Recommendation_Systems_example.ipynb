{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender Systems - Following Grus'  DS book (with some changes in the code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. User-Based collaborative filtering:\n",
    "\n",
    "We have a set of users, where the users list their preferences. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "users_interests = [\n",
    "    [\"Hadoop\", \"Big Data\", \"HBase\", \"Java\", \"Spark\", \"Storm\", \"Cassandra\"],\n",
    "    [\"NoSQL\", \"MongoDB\", \"Cassandra\", \"HBase\", \"Postgres\"],\n",
    "    [\"Python\", \"scikit-learn\", \"scipy\", \"numpy\", \"statsmodels\", \"pandas\"],\n",
    "    [\"R\", \"Python\", \"statistics\", \"regression\", \"probability\"],\n",
    "    [\"machine learning\", \"regression\", \"decision trees\", \"libsvm\"],\n",
    "    [\"Python\", \"R\", \"Java\", \"C++\", \"Haskell\", \"programming languages\"],\n",
    "    [\"statistics\", \"probability\", \"mathematics\", \"theory\"],\n",
    "    [\"machine learning\", \"scikit-learn\", \"Mahout\", \"neural networks\"],\n",
    "    [\"neural networks\", \"deep learning\", \"Big Data\", \"artificial intelligence\"],\n",
    "    [\"Hadoop\", \"Java\", \"MapReduce\", \"Big Data\"],\n",
    "    [\"statistics\", \"R\", \"statsmodels\"],\n",
    "    [\"C++\", \"deep learning\", \"artificial intelligence\", \"probability\"],\n",
    "    [\"pandas\", \"R\", \"Python\"],\n",
    "    [\"databases\", \"HBase\", \"Postgres\", \"MySQL\", \"MongoDB\"],\n",
    "    [\"libsvm\", \"regression\", \"support vector machines\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is straightforward to interpret the User/Item descriptions as a matrix. Next, we need a measure of similitude between two users. A simple metric such as the dot product can be used to quantify user similitude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def cosine_similarity(v, w):\n",
    "    return np.dot(v,w)/(np.linalg.norm(v)*np.linalg.norm(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each user entry is a n-th component vector. The dimension of the vector space depends on the number of unique interests, so we need to find the set of unique interests, and then assign a vector component to each of these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "unique_interests = sorted(list(set([interest for user in users_interests for interest in user])))\n",
    "n = len(unique_interests)\n",
    "print n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with the set of unique interests, we can define a function that converts each user interest list in a n-th (36-th) dimensional vector to compute cosine similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_num_vector(user):\n",
    "    out = [1 if interest in user else 0 for interest in unique_interests]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can calculate the similarity matrix between users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_similarities = [[cosine_similarity(get_num_vector(interest_vector_i), get_num_vector(interest_vector_j)) \\\n",
    "                      for interest_vector_i in users_interests] for interest_vector_j in users_interests]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can quantify similitude between users, which we need to make recommendations based on this. We proceed by defining a function that finds the most similar users to a given user (user_id):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def most_similar_users_to(user_id):\n",
    "    return sorted([(user, score) for (user, score) in enumerate(user_similarities[user_id])\n",
    "           if user_id != user and score >0], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9, 0.56694670951384085),\n",
       " (1, 0.33806170189140655),\n",
       " (8, 0.1889822365046136),\n",
       " (13, 0.16903085094570328),\n",
       " (5, 0.15430334996209191)]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_users_to(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with the similitude, we can make our recommendations. For each interest, we add the user similitudes of other users, and make a suggestion based on this score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def user_based_suggestions(user_id, include_current_interests = False):\n",
    "    recommendations = {interest: 0 for interest in unique_interests}  #Create dict of interests/scores to be populated\n",
    "    for other_user, score in most_similar_users_to(user_id):\n",
    "        for interest in users_interests[other_user]:\n",
    "            if include_current_interests:\n",
    "                recommendations[interest] += score\n",
    "            else:\n",
    "                if interest not in users_interests[user_id]:\n",
    "                    recommendations[interest] += score\n",
    "    return sorted([(key, value) for key, value in recommendations.items()], key = lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for user 0 we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('MapReduce', 0.56694670951384085),\n",
       " ('Postgres', 0.50709255283710986),\n",
       " ('MongoDB', 0.50709255283710986),\n",
       " ('NoSQL', 0.33806170189140655),\n",
       " ('neural networks', 0.1889822365046136),\n",
       " ('deep learning', 0.1889822365046136),\n",
       " ('artificial intelligence', 0.1889822365046136),\n",
       " ('MySQL', 0.16903085094570328),\n",
       " ('databases', 0.16903085094570328),\n",
       " ('programming languages', 0.15430334996209191),\n",
       " ('Python', 0.15430334996209191),\n",
       " ('C++', 0.15430334996209191),\n",
       " ('R', 0.15430334996209191),\n",
       " ('Haskell', 0.15430334996209191),\n",
       " ('Java', 0),\n",
       " ('Hadoop', 0),\n",
       " ('Mahout', 0),\n",
       " ('Storm', 0),\n",
       " ('regression', 0),\n",
       " ('statistics', 0),\n",
       " ('scipy', 0),\n",
       " ('mathematics', 0),\n",
       " ('Spark', 0),\n",
       " ('numpy', 0),\n",
       " ('pandas', 0),\n",
       " ('theory', 0),\n",
       " ('libsvm', 0),\n",
       " ('probability', 0),\n",
       " ('HBase', 0),\n",
       " ('decision trees', 0),\n",
       " ('Big Data', 0),\n",
       " ('scikit-learn', 0),\n",
       " ('machine learning', 0),\n",
       " ('statsmodels', 0),\n",
       " ('support vector machines', 0),\n",
       " ('Cassandra', 0)]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_based_suggestions(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Item-based collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed by Grus, if the dimensionality of the vector space becomes too large then the similitude between users is hard to quantify (curse of dimensionality). An alternative approach is to use Item-based collaborative filtering. We determine the similitude between items directly, using the user/item matrix. We start by transposing the user interest matrix (which we did not calculate before but is pretty straightforward):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_interest_matrix = [get_num_vector(user) for user in users_interests]\n",
    "interest_user_matrix = [[user_interest_vector[j] for user_interest_vector in user_interest_matrix] for j in range(len(unique_interests))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we proceed as before, using cosine similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interest_similarities = [[cosine_similarity(user_vector_i, user_vector_j) for user_vector_i in interest_user_matrix] \n",
    "                         for user_vector_j in interest_user_matrix]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we use the same code for User-based recommendations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_similar_interests_to(interest_id):\n",
    "    return sorted([(unique_interests[interest], score) for (interest, score) in enumerate(interest_similarities[interest_id])\n",
    "           if interest_id != interest and score >0], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hadoop', 0.81649658092772592),\n",
       " ('Java', 0.66666666666666674),\n",
       " ('MapReduce', 0.57735026918962584),\n",
       " ('Spark', 0.57735026918962584),\n",
       " ('Storm', 0.57735026918962584),\n",
       " ('Cassandra', 0.40824829046386296),\n",
       " ('artificial intelligence', 0.40824829046386296),\n",
       " ('deep learning', 0.40824829046386296),\n",
       " ('neural networks', 0.40824829046386296),\n",
       " ('HBase', 0.33333333333333337)]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_interests_to(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for every user we can find the best recommendations based on this similarity scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def item_based_suggestions(user_id, include_current_interests = False):\n",
    "    recommendations = {interest: 0 for interest in unique_interests}  #Create dict of interests/scores to be populated\n",
    "    for interests in users_interests[user_id]:\n",
    "        for similar_interests, score in most_similar_interests_to(unique_interests.index(interests)):\n",
    "            if include_current_interests:\n",
    "                recommendations[similar_interests] += score\n",
    "            else:\n",
    "                if similar_interests not in users_interests[user_id]:\n",
    "                    recommendations[similar_interests] += score\n",
    "    return sorted([(key, value) for key, value in recommendations.items()], key = lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('MapReduce', 1.8618073195657989),\n",
       " ('Postgres', 1.3164965809277258),\n",
       " ('MongoDB', 1.3164965809277258),\n",
       " ('NoSQL', 1.2844570503761732),\n",
       " ('MySQL', 0.57735026918962584),\n",
       " ('programming languages', 0.57735026918962584),\n",
       " ('Haskell', 0.57735026918962584),\n",
       " ('databases', 0.57735026918962584),\n",
       " ('neural networks', 0.40824829046386296),\n",
       " ('deep learning', 0.40824829046386296),\n",
       " ('artificial intelligence', 0.40824829046386296),\n",
       " ('C++', 0.40824829046386296),\n",
       " ('Python', 0.28867513459481292),\n",
       " ('R', 0.28867513459481292),\n",
       " ('Java', 0),\n",
       " ('Hadoop', 0),\n",
       " ('Mahout', 0),\n",
       " ('Storm', 0),\n",
       " ('regression', 0),\n",
       " ('statistics', 0),\n",
       " ('scipy', 0),\n",
       " ('mathematics', 0),\n",
       " ('Spark', 0),\n",
       " ('numpy', 0),\n",
       " ('pandas', 0),\n",
       " ('theory', 0),\n",
       " ('libsvm', 0),\n",
       " ('probability', 0),\n",
       " ('HBase', 0),\n",
       " ('decision trees', 0),\n",
       " ('Big Data', 0),\n",
       " ('scikit-learn', 0),\n",
       " ('machine learning', 0),\n",
       " ('statsmodels', 0),\n",
       " ('support vector machines', 0),\n",
       " ('Cassandra', 0)]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_based_suggestions(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [insight_project]",
   "language": "python",
   "name": "Python [insight_project]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
