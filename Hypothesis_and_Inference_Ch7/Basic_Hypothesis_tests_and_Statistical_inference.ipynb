{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of basics of Hypothesis and Inference - From Grus' book (with small changes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The binomial distribution arises as the sum of bernoulli random variables. Using the central limit theorem, we know that this sum is a random variable with distribution approaching the normal distribution, mean = n*p and variance = n*p*(1-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normal_approximation_to_binomial(n, p):\n",
    "    \"\"\"finds mu and sigma corresponding to a Binomial(n, p)\"\"\"\n",
    "    mu = p * n\n",
    "    sigma = math.sqrt(p * (1 - p) * n)\n",
    "    return mu, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other basic concepts covered are the CDF (cummulative density function) which determines P(X < x), the probability that the random variable X will be below x. Other definitions can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def normal_cdf(hi, mu=0, sigma=1):\n",
    "    return norm.cdf(hi, loc = mu, scale = sigma)\n",
    "\n",
    "# the normal cdf _is_ the probability the variable is below a threshold\n",
    "normal_probability_below = normal_cdf\n",
    "\n",
    "# it's above the threshold if it's not below the threshold\n",
    "def normal_probability_above(lo, mu=0, sigma=1):\n",
    "    return 1 - normal_cdf(lo, mu, sigma)\n",
    "    \n",
    "# it's between if it's less than hi, but not less than lo\n",
    "def normal_probability_between(lo, hi, mu=0, sigma=1):\n",
    "    return normal_cdf(hi, mu, sigma) - normal_cdf(lo, mu, sigma)\n",
    "\n",
    "# it's outside if it's not between\n",
    "def normal_probability_outside(lo, hi, mu=0, sigma=1):\n",
    "    return 1 - normal_probability_between(lo, hi, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also find inverse of CDF, which gives us ranges of values for a random variable X, \n",
    "for a given probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inverse_normal_cdf(prob, mu, sigma):\n",
    "    return norm.ppf(prob , loc= mu, scale=sigma)\n",
    "\n",
    "def normal_upper_bound(probability, mu=0, sigma=1):\n",
    "    \"\"\"returns the z for which P(Z <= z) = probability\"\"\"\n",
    "    return inverse_normal_cdf(probability, mu, sigma)\n",
    "    \n",
    "def normal_lower_bound(probability, mu=0, sigma=1):\n",
    "    \"\"\"returns the z for which P(Z >= z) = probability\"\"\"\n",
    "    return inverse_normal_cdf(1 - probability, mu, sigma)\n",
    "\n",
    "def normal_two_sided_bounds(probability, mu=0, sigma=1):\n",
    "    \"\"\"returns the symmetric (about the mean) bounds \n",
    "    that contain the specified probability\"\"\"\n",
    "    tail_probability = (1 - probability) / 2\n",
    "\n",
    "    # upper bound should have tail_probability above it\n",
    "    upper_bound = normal_lower_bound(tail_probability, mu, sigma)\n",
    "\n",
    "    # lower bound should have tail_probability below it\n",
    "    lower_bound = normal_upper_bound(tail_probability, mu, sigma)\n",
    "\n",
    "    return lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These definitions are useful for hypothesis testing, as we will see... Confidence intervals are strongly related with probability intervals (particularly when discussing the significance of a test). \n",
    "\n",
    "Let's run a simple hypothesis test. Let's say we want to determine wheter a coin is fair or not. \n",
    "\n",
    "Our null hypothesis should be Ho : p = 0.5. The alternative hypothesis is that p != 0.5. Let's say that we run the experiment 1000 times. \n",
    "\n",
    "We accept the null hypothesis as valid, and then determine how willing are we to have a type I error, i.e., a false positive. This determines the SIGNIFICANCE of a test. For a 5% of significance, in 1000 flips we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Accept Ho as valid, find the parameters for the normal that approaches a binomial:\n",
    "mu_0, sigma_0 = normal_approximation_to_binomial(1000, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(469.0102483847719, 530.9897516152281)\n"
     ]
    }
   ],
   "source": [
    "#Find the lower and upper bounds for a significance of 5% on a 1000-flip experiment:\n",
    "print normal_two_sided_bounds(0.95, mu_0, sigma_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means, that if we carry on the experiment and we find a number of fips within this window, we accept Ho as valid with 5% significance.\n",
    "\n",
    "The significance of a test is just part of the story. We also have the POWER of a test, which is the one minus the probability of having a false negative (fail to reject Ho when Ho is false).\n",
    "\n",
    "Let's say that p =0.55. What is the power of the test in this case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.886547781098\n"
     ]
    }
   ],
   "source": [
    "#Accept Ho as valid, find the parameters for the normal that approaches a binomial:\n",
    "lo, hi = normal_two_sided_bounds(0.95, mu_0, sigma_0)\n",
    "\n",
    "#But, Ho is false, so find the parameters for the normal that approaches a binomial:\n",
    "mu_1, sigma_1 = normal_approximation_to_binomial(1000, 0.55)\n",
    "\n",
    "#What is the probabilty of falling within the Ho acceptance interval, even though Ho is not valid?\n",
    "type_2_probability = normal_probability_between(lo, hi, mu_1, sigma_1)\n",
    "\n",
    "power = 1 - type_2_probability\n",
    "print power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more powerful test is a ONE-SIDED test. Instead of testing whether p!=0.5, we can test whether the coin is biased towards more heads (p>0.5). This increases the power of the test, because the 5% tail involved in the calculation is only one sided, so the upper bound for rejection is lower:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "526.00741939377792"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.ppf(0.95, loc=mu_0, scale=sigma_0) #Number of heads for rejection of Ho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the power of the one sided test is (prob of accepting Ho even when Ha is true):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.936437785529\n"
     ]
    }
   ],
   "source": [
    "print 1-normal_probability_below(526, mu_1, sigma_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "An alternative (and more commonly used) approach to hypothesis testing is to find the probability of finding a value at least as extreme as the observation. Then, this probability is compared with the significance of the test for rejection/acceptance of the null hypothesis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def two_sided_p_value(x, mu=0, sigma=1):\n",
    "    if x >= mu:\n",
    "        # if x is greater than the mean, the tail is above x\n",
    "        return 2 * normal_probability_above(x, mu, sigma)\n",
    "    else:\n",
    "        # if x is less than the mean, the tail is below x\n",
    "        return 2 * normal_probability_below(x, mu, sigma)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, for 530 heads we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06207721579598835"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_sided_p_value(529.5, mu_0, sigma_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confidence intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative approach to statistical inference is using confidence intervals. We estimate a parameter of the population and give an interval around the parameter.\n",
    "\n",
    "For example, let's assume that we get 525 heads from 1000 flips, so that we estimate p=0.525.\n",
    "\n",
    "Per central limit theorem we obtain the confidence interval for the p parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.49404900981534522, 0.55595099018465477)\n"
     ]
    }
   ],
   "source": [
    "print normal_two_sided_bounds(0.95, 0.525, math.sqrt(0.525*(1-0.525)/1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the confidence interval says that if you were to repeat the experiment 100 times, 95 percent of the times your estimate for p will fall within this interval (the interval itself is different for each experiment)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A/B testing\n",
    "\n",
    "Let's suppose that we have 2 websites, site A and site B. We want to determine if an ad presented in both sites is more effective in one of the sites. This is a hypothesis testing, where we should test if the ad click rates coming from the sites are different. \n",
    "\n",
    "The null hypothesis is Ra=Rb, the alternative hypothesis is Ra!=Rb. We perform the experiment 1000 times per site. This is a tow sample test, where we should use the following statistical parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##\n",
    "#\n",
    "# running an A/B test\n",
    "#\n",
    "##\n",
    "\n",
    "def estimated_parameters(N, n):  #Estimated parameters for a site\n",
    "    p = n / N   #Ad click rate\n",
    "    sigma = math.sqrt(p * (1 - p) / N) #sigma\n",
    "    return p, sigma\n",
    "\n",
    "#Define test statistic:\n",
    "def a_b_test_statistic(N_A, n_A, N_B, n_B):\n",
    "    p_A, sigma_A = estimated_parameters(N_A, n_A)\n",
    "    p_B, sigma_B = estimated_parameters(N_B, n_B)\n",
    "    return (p_B - p_A) / math.sqrt(sigma_A ** 2 + sigma_B ** 2) #Variances added in quadrature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis is that p_B=p_A. Let's assume that after the experiment, we find n_a = 200 and n_b = 180:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25414197654223603"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_sided_p_value(a_b_test_statistic(1000,200,1000,180))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of finding this difference is of 0.25. So we don't reject the null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redoing this section with python modules\n",
    "\n",
    "Let's try to reproduce everything, with only python modules, not to reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stats module has statistical tests...and normal distribution\n",
    "from scipy.stats import norm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found previously that if we flip a coin 1000, a hypothesis test for fairness with 5% significance would find (469.0102483847719, 530.9897516152281) as the number of heads (or tails). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_1sampResult(statistic=1.9634089034286304, pvalue=0.049875746922877176)\n",
      "Ttest_1sampResult(statistic=-1.8998404716564716, pvalue=0.057741809969881409)\n"
     ]
    }
   ],
   "source": [
    "#two tailed p-value for 530 flips:\n",
    "print stats.ttest_1samp([1 if x < 531 else 0 for x in range(1000)], 0.5)\n",
    "print stats.ttest_1samp([1 if x < 470 else 0 for x in range(1000)], 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the p values... 0.05 as previosly found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_1sampResult(statistic=1.6457885978381699, pvalue=0.10012184152590092)\n"
     ]
    }
   ],
   "source": [
    "#one tailed p-value:\n",
    "print stats.ttest_1samp([1 if x < 526 else 0 for x in range(1000)], 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A one tailed test can be reproduced from a symmetric 2 tailed test. Just divide the p value by 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For confidence intervals, we use norm.interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.49404900981534522, 0.55595099018465477)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.norm.interval(0.95, loc=0.525, scale=math.sqrt(0.525*(1-0.525)/1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, for a two sample t test, such as A/B testing of a website:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=1.1397761740438677, pvalue=0.2545161805191154)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind([1 if x < 200 else 0 for x in range(1000)], [1 if x < 180 else 0 for x in range(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [insight_project]",
   "language": "python",
   "name": "Python [insight_project]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
